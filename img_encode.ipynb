{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-20T04:32:38.678700400Z",
     "start_time": "2024-01-20T04:32:35.141090100Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_csv('prepared_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T04:32:48.585281900Z",
     "start_time": "2024-01-20T04:32:38.679701Z"
    }
   },
   "id": "c696b2f7210028dd"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "test = pd.read_csv('prepared_test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:43:03.695062300Z",
     "start_time": "2024-01-20T06:43:03.559135300Z"
    }
   },
   "id": "7f6b0bb00ef5caa6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "mapping = pd.read_csv('mapping_ids.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T04:32:48.646570500Z",
     "start_time": "2024-01-20T04:32:48.587284400Z"
    }
   },
   "id": "b599a3123486a0bc"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "TRAIN_IMG = 'train_images_archive/'\n",
    "TEST_IMG = 'test_images_archive/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:45:57.123215800Z",
     "start_time": "2024-01-20T06:45:57.111811600Z"
    }
   },
   "id": "2dbad52792b55004"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleks\\anaconda3\\Lib\\site-packages\\transformers\\models\\vit\\feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "\n",
    "extractor = AutoFeatureExtractor.from_pretrained(\"therealcyberlord/stanford-car-vit-patch16\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"therealcyberlord/stanford-car-vit-patch16\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T04:32:51.870882Z",
     "start_time": "2024-01-20T04:32:48.656524600Z"
    }
   },
   "id": "d778864f4b9cbd24"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def get_img_embedding(id):\n",
    "    embedding = np.zeros((1, 197, 768))\n",
    "    count = 0\n",
    "    img_ids = mapping[mapping['id'] == id]['image_id']\n",
    "    for img_id in img_ids:\n",
    "        try:\n",
    "            image = Image.open(TRAIN_IMG + str(img_id) + '.jpg')\n",
    "            inputs = extractor(images=image, return_tensors='pt')\n",
    "            inputs = {name: tensor.to('cuda') for name, tensor in inputs.items()}\n",
    "            outputs = model.base_model(**inputs)\n",
    "            embedding += outputs.last_hidden_state.cpu().detach().numpy()\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return embedding.mean(axis=1).flatten() / (count if count > 0 else 1)\n",
    "\n",
    "def get_test_img_embedding(id):\n",
    "    embedding = np.zeros((1, 197, 768))\n",
    "    count = 0\n",
    "    img_ids = mapping[mapping['id'] == id]['image_id']\n",
    "    for img_id in img_ids:\n",
    "        try:\n",
    "            image = Image.open(TEST_IMG + str(img_id) + '.jpg')\n",
    "            inputs = extractor(images=image, return_tensors='pt')\n",
    "            inputs = {name: tensor.to('cuda') for name, tensor in inputs.items()}\n",
    "            outputs = model.base_model(**inputs)\n",
    "            embedding += outputs.last_hidden_state.cpu().detach().numpy()\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return embedding.mean(axis=1).flatten() / (count if count > 0 else 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T07:17:08.962320300Z",
     "start_time": "2024-01-20T07:17:08.949973900Z"
    }
   },
   "id": "ed58120c1c761610"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T04:38:59.257114600Z",
     "start_time": "2024-01-20T04:38:59.246606300Z"
    }
   },
   "id": "13f819bac8a5faa6"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "ViTForImageClassification(\n  (vit): ViTModel(\n    (embeddings): ViTEmbeddings(\n      (patch_embeddings): ViTPatchEmbeddings(\n        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): ViTEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x ViTLayer(\n          (attention): ViTAttention(\n            (attention): ViTSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): ViTSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): ViTIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): ViTOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n  )\n  (classifier): Linear(in_features=768, out_features=196, bias=True)\n)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to('cuda')\n",
    "model.base_model.eval()\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T04:38:59.430201600Z",
     "start_time": "2024-01-20T04:38:59.414656500Z"
    }
   },
   "id": "b3968232b9926c9d"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    data_img_embeddings = data['id'].apply(get_img_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:39:51.187675100Z",
     "start_time": "2024-01-20T04:47:28.524062500Z"
    }
   },
   "id": "eefb5fa9e978a4c1"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "embeddings_matrix = np.array(data_img_embeddings.tolist())\n",
    "\n",
    "# Initialize PCA\n",
    "pca = PCA(n_components=128)\n",
    "\n",
    "# Fit and transform the data\n",
    "reduced_embeddings = pca.fit_transform(embeddings_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:40:36.975372400Z",
     "start_time": "2024-01-20T06:39:51.257060700Z"
    }
   },
   "id": "de431250dc43ac72"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "np.save('img_embeddings.npy', reduced_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:40:41.413746Z",
     "start_time": "2024-01-20T06:40:36.984697600Z"
    }
   },
   "id": "ab8e95e8ac8e1317"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "del data_img_embeddings\n",
    "del embeddings_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T06:43:24.496061700Z",
     "start_time": "2024-01-20T06:43:19.013497600Z"
    }
   },
   "id": "2e25658c8e1a4cfc"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_img_embeddings = test['id'].apply(get_test_img_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T08:01:46.692984900Z",
     "start_time": "2024-01-20T07:17:21.233236500Z"
    }
   },
   "id": "667569d3e175299d"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "embeddings_matrix = np.array(test_img_embeddings.tolist())\n",
    "reduced_embeddings = pca.transform(embeddings_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T08:01:46.721078200Z",
     "start_time": "2024-01-20T08:01:46.687479400Z"
    }
   },
   "id": "6cbc13b608a32a79"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "np.save('test_img_embeddings.npy', reduced_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T08:01:46.722647100Z",
     "start_time": "2024-01-20T08:01:46.713960500Z"
    }
   },
   "id": "df813b03abc6d017"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31      [-0.6503347507754548, 0.41770094290664583, 0.1...\n",
      "168     [-0.20116988210982534, 0.2564373272659903, 0.3...\n",
      "223     [-0.01812519282623269, 0.23617112564138168, -0...\n",
      "325     [-0.015530212395718123, 0.8052608835690164, 0....\n",
      "430     [0.009833476389471928, 0.41649819359830814, -0...\n",
      "437     [-0.5263142807433884, 0.5468882173018395, -0.3...\n",
      "447     [0.16715555636641843, 0.29856856315957286, -0....\n",
      "471     [0.13455632621388067, 0.3916310768624672, -0.3...\n",
      "502     [-0.5850567846782908, 0.45216989319586565, 0.0...\n",
      "521     [-0.5947344552093691, 0.4608764386721859, 0.12...\n",
      "600     [-0.01810001980494941, 0.3005775533261923, 0.2...\n",
      "659     [-0.04033050550249763, 0.40188624662734507, -0...\n",
      "717     [-0.02304378238760655, 0.28246198238952674, 0....\n",
      "743     [-0.24775981457517948, 0.2860230819318402, 0.0...\n",
      "859     [-0.04446852575481732, 0.6772535775876178, -0....\n",
      "1000    [-0.08668337500872215, 0.21097299145680973, 0....\n",
      "Name: id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# get rows with not all zeros\n",
    "\n",
    "print(data_img_embeddings[data_img_embeddings.apply(lambda x: np.sum(x) != 0)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T04:39:21.781947800Z",
     "start_time": "2024-01-20T04:39:21.755084800Z"
    }
   },
   "id": "b0c6f4e3397ebbcb"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "? model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T20:19:41.208969200Z",
     "start_time": "2024-01-19T20:19:41.184326800Z"
    }
   },
   "id": "f7404ddb59f70388"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
